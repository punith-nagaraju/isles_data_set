{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65934b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import ISLES2p5DDataset\n",
    "from src.augmentations import get_train_augmentations\n",
    "from src.model import get_unet\n",
    "from src.ensemble import load_ensemble, ensemble_predict\n",
    "from src.utils import dice_score, plot_sample\n",
    "\n",
    "# 1. Set up paths and parameters\n",
    "DATA_DIR = \"../data\"  # or your actual data folder path\n",
    "N_MODELS = 3\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. Prepare dataset and dataloader\n",
    "train_dataset = ISLES2p5DDataset(\n",
    "    root_dir=DATA_DIR,\n",
    "    modalities=['dwi', 'adc', 'flair'],\n",
    "    slice_axis=2,\n",
    "    slice_depth=3,\n",
    "    transform=get_augmentation_pipeline(),\n",
    "    resize=(128, 128)  # or (192, 192), but always fixed!\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "# 3. Train multiple base models for ensemble\n",
    "for i in range(N_MODELS):\n",
    "    model = get_unet(in_channels=9).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE, dtype=torch.float), y.to(DEVICE, dtype=torch.float)\n",
    "            y = y.unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            bce = torch.nn.BCELoss()\n",
    "            loss = 0.5 * bce(out, y) + 0.5 * (1 - dice_score(out, y))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    torch.save(model.state_dict(), f\"base_model_{i}.pth\")\n",
    "    print(f\"Saved base_model_{i}.pth\")\n",
    "\n",
    "# 4. Load ensemble models\n",
    "model_paths = [f\"base_model_{i}.pth\" for i in range(N_MODELS)]\n",
    "ensemble_models = load_ensemble(model_paths, DEVICE)\n",
    "\n",
    "# 5. Ensemble prediction on a batch\n",
    "x, y = next(iter(train_loader))\n",
    "x = x.to(DEVICE, dtype=torch.float)\n",
    "final_mask, averaged_probs = ensemble_predict(ensemble_models, x)\n",
    "\n",
    "# 6. Evaluate and visualize\n",
    "for i in range(min(3, x.shape[0])):  # Show up to 3 samples\n",
    "    print(f\"Dice score (ensemble): {dice_score(final_mask[i], y[i])}\")\n",
    "    plot_sample(x[i].cpu(), y[i].cpu(), final_mask[i].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd58c3e-404e-421a-b68a-0a3b26d1afdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a4823-a66e-46bc-b1e9-5778255032a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
