{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "65934b82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65934b82",
        "outputId": "dfc5093a-fb30-44d8-bd27-e6d19cebfaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement as (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for as\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement albumentations.pytorch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for albumentations.pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement as (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for as\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "All devices: []\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement as (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for as\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.14.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.4.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (11.2.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.5.3)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.4.26)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: segmentation_models_pytorch\n",
            "Successfully installed segmentation_models_pytorch-0.5.0\n",
            "Imports done\n",
            "Prepare dataset and dataloader cuda\n",
            "Mounted at /content/drive\n",
            "data\n",
            "src\n",
            "entering 3D samples\n",
            "Total 3D samples: 250\n",
            "Sample mask unique: tensor([0., 1.])\n",
            "Number of samples in dataset: 250\n",
            "Number of batches in DataLoader: 84\n",
            "#Train multiple base models for ensemble\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_unet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1785599649>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"#Train multiple base models for ensemble\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_unet' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install albumentations as A\n",
        "!pip install albumentations.pytorch import ToTensorV2\n",
        "from google.colab import drive\n",
        "print(f\"Imports done\")\n",
        "# 1. Set up paths and parameters\n",
        "DATA_DIR = \"/content/drive/My Drive/data/ISLES-2022\"  # or your actual data folder path\n",
        "N_MODELS = 3\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_train_augmentations():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ElasticTransform(p=0.2),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.Normalize(mean=0, std=1, max_pixel_value=1.0),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "import os\n",
        "!pip install numpy as np\n",
        "!pip install nibabel\n",
        "import nibabel as nib\n",
        "!pip install torch\n",
        "from torch.utils.data import Dataset\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(\"All devices:\", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "class ISLESDataset3D(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.samples = []\n",
        "        print(f\"entering 3D samples\")\n",
        "        mask_root = os.path.join(root_dir, \"derivatives\")\n",
        "        for subject in os.listdir(root_dir):\n",
        "            if subject.startswith(\"sub-\"):\n",
        "                ses_dir = os.path.join(root_dir, subject, \"ses-0001\")\n",
        "                if os.path.exists(ses_dir):\n",
        "                    dwi_dir = os.path.join(ses_dir, \"dwi\")\n",
        "                    anat_dir = os.path.join(ses_dir, \"anat\")\n",
        "                    dwi_path = [f for f in os.listdir(dwi_dir) if f.endswith(\"_dwi.nii.gz\")]\n",
        "                    flair_path = [f for f in os.listdir(anat_dir) if f.endswith(\"_FLAIR.nii.gz\")]\n",
        "                    mask_dir = os.path.join(mask_root, subject, \"ses-0001\")\n",
        "                    mask_path = []\n",
        "                    if os.path.exists(mask_dir):\n",
        "                        mask_path = [f for f in os.listdir(mask_dir) if f.endswith(\".nii.gz\")]\n",
        "                    if dwi_path and flair_path and mask_path:\n",
        "                        self.samples.append({\n",
        "                            \"dwi\": os.path.join(dwi_dir, dwi_path[0]),\n",
        "                            \"flair\": os.path.join(anat_dir, flair_path[0]),\n",
        "                            \"mask\": os.path.join(mask_dir, mask_path[0])\n",
        "                        })\n",
        "        print(f\"Total 3D samples: {len(self.samples)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        dwi = self.load_nifti(sample[\"dwi\"])    # [H, W, D]\n",
        "        flair = self.load_nifti(sample[\"flair\"])  # [H, W, D]\n",
        "\n",
        "        # Crop both to the minimum shape\n",
        "        min_shape = np.minimum(dwi.shape, flair.shape)\n",
        "        dwi_cropped = dwi[:min_shape[0], :min_shape[1], :min_shape[2]]\n",
        "        flair_cropped = flair[:min_shape[0], :min_shape[1], :min_shape[2]]\n",
        "\n",
        "        x = np.stack([dwi_cropped, flair_cropped], axis=0)  # [2, H, W, D]\n",
        "        y = self.load_nifti(sample[\"mask\"])\n",
        "        y = y[:min_shape[0], :min_shape[1], :min_shape[2]]  # Crop mask to match\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nifti(path):\n",
        "        return np.asarray(nib.load(path).get_fdata(), dtype=np.float32)\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels=2, out_channels=1, features=[32, 64, 128, 256]):\n",
        "        super().__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        # Down part\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv3D(in_channels, feature))\n",
        "            in_channels = feature\n",
        "        self.bottleneck = DoubleConv3D(features[-1], features[-1]*2)\n",
        "        in_channels = features[-1]*2  # after bottleneck\n",
        "\n",
        "        # Up part (only ONCE!)\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose3d(in_channels, feature, kernel_size=2, stride=2))\n",
        "            self.ups.append(DoubleConv3D(feature * 2, feature))\n",
        "            in_channels = feature  # update for next up block\n",
        "\n",
        "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = F.max_pool3d(x, 2)\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip = skip_connections[idx // 2]\n",
        "            # Pad if needed\n",
        "            diffD = skip.shape[2] - x.shape[2]\n",
        "            diffH = skip.shape[3] - x.shape[3]\n",
        "            diffW = skip.shape[4] - x.shape[4]\n",
        "            x = F.pad(\n",
        "                x,\n",
        "                [diffW // 2, diffW - diffW // 2,\n",
        "                 diffH // 2, diffH - diffH // 2,\n",
        "                 diffD // 2, diffD - diffD // 2]\n",
        "            )\n",
        "            # Crop if needed (for negative diffs)\n",
        "            if x.shape[2] > skip.shape[2]:\n",
        "                x = x[:, :, :skip.shape[2], :, :]\n",
        "            if x.shape[3] > skip.shape[3]:\n",
        "                x = x[:, :, :, :skip.shape[3], :]\n",
        "            if x.shape[4] > skip.shape[4]:\n",
        "                x = x[:, :, :, :, :skip.shape[4]]\n",
        "            # Debug print\n",
        "            print(\"skip shape:\", skip.shape)\n",
        "            print(\"x shape:\", x.shape)\n",
        "            x = torch.cat((skip, x), dim=1)\n",
        "            x = self.ups[idx + 1](x)\n",
        "        return torch.sigmoid(self.final_conv(x))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_unet(in_channels=2, out_channels=1):\n",
        "      return UNet3D(in_channels=in_channels, out_channels=out_channels)\n",
        "\n",
        "import torch\n",
        "\n",
        "def load_ensemble(model_paths, device):\n",
        "    models = []\n",
        "    for path in model_paths:\n",
        "        model = get_unet()\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "        models.append(model)\n",
        "    return models\n",
        "\n",
        "def ensemble_predict(models, x):\n",
        "    with torch.no_grad():\n",
        "        preds = [model(x) for model in models]\n",
        "    stacked = torch.stack(preds, dim=0)\n",
        "    avg = torch.mean(stacked, dim=0)\n",
        "    final = (avg > 0.5).float()\n",
        "    return final, avg\n",
        "\n",
        "\n",
        "# File: /isles22-ensemble-segmentation/isles22-ensemble-segmentation/src/predict.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "!pip install nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_and_show_ensemble(data_folder, model_paths, idx=0, slice_idx=None):\n",
        "    dataset = ISLESDataset3D(data_folder)\n",
        "    if len(dataset) == 0:\n",
        "        print(\"No samples found.\")\n",
        "        return\n",
        "\n",
        "    models = load_models(model_paths)\n",
        "    ensemble_model = EnsembleSegmentationModel(models)\n",
        "\n",
        "    x, y = dataset[idx]\n",
        "    x = x.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = ensemble_model(x)\n",
        "\n",
        "    pred_np = pred.squeeze().numpy()\n",
        "    flair_np = x[0, 1].numpy()\n",
        "    mask_np = y.numpy()\n",
        "\n",
        "    # Choose a slice index (center if not specified)\n",
        "    if slice_idx is None:\n",
        "        slice_idx = flair_np.shape[2] // 2\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"FLAIR (center slice)\")\n",
        "    plt.imshow(flair_np[:, :, slice_idx], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.imshow(mask_np[:, :, slice_idx], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Ensemble Predicted Mask\")\n",
        "    plt.imshow(pred_np[:, :, slice_idx], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def dice_loss(pred, target, smooth=1.):\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "    intersection = (pred * target).sum()\n",
        "    return 1 - ((2. * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    bce = nn.BCELoss()\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE, dtype=torch.float), y.to(DEVICE, dtype=torch.float)\n",
        "        x = x[..., x.shape[-1] // 2]\n",
        "        y = y[..., y.shape[-1] // 2]\n",
        "        if x.shape[1] > 2:\n",
        "             x = x[:, :2, ...]\n",
        "        y = y.unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = 0.5 * bce(out, y) + 0.5 * dice_loss(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def train_ensemble(data_dir, n_models=3, epochs=2, batch_size=8):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    loader = get_dataloaders(data_dir, batch_size)\n",
        "    for i in range(n_models):\n",
        "        model = UNet3D.get_unet().to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "        for epoch in range(epochs):\n",
        "            train_one_epoch(model, loader, optimizer, device)\n",
        "        torch.save(model.state_dict(), f\"base_model_{i}.pth\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dice_score(pred, target, smooth=1.):\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "    intersection = (pred * target).sum()\n",
        "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "\n",
        "def plot_sample(x, y, pred, channel=0):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Input (selected channel)\")\n",
        "    plt.imshow(x[channel].cpu(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.imshow(y.squeeze().cpu(), cmap='gray')  # <--- fix here\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.imshow(pred.squeeze().cpu(), cmap='gray')  # <--- fix here\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "%pip install nibabel\n",
        "%pip install opencv-python\n",
        "%pip install albumentations\n",
        "%pip install segmentation_models_pytorch\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "\n",
        "def safe_unsqueeze_mask(y):\n",
        "    # Ensure mask is [B, 1, D, H, W]\n",
        "    if y.ndim == 4:\n",
        "        y = y.unsqueeze(1)\n",
        "    elif y.ndim == 5 and y.shape[1] != 1:\n",
        "        # If mask has extra channels, take the first\n",
        "        y = y[:, :1, ...]\n",
        "    elif y.ndim < 4:\n",
        "        raise ValueError(f\"Mask shape too small: {y.shape}\")\n",
        "    return y\n",
        "\n",
        "def safe_pad_or_crop(x, target_shape):\n",
        "    # Accepts [B, C, D, H, W] or [B, D, H, W] or [C, D, H, W]\n",
        "    if x.ndim == 4:\n",
        "        x = x.unsqueeze(0)  # Add batch dim if missing\n",
        "    if x.ndim == 5:\n",
        "        _, _, D, H, W = x.shape\n",
        "        tD, tH, tW = target_shape\n",
        "        pad_d = max(tD - D, 0)\n",
        "        pad_h = max(tH - H, 0)\n",
        "        pad_w = max(tW - W, 0)\n",
        "        x = F.pad(x, [0, pad_w, 0, pad_h, 0, pad_d])\n",
        "        x = x[:, :, :tD, :tH, :tW]\n",
        "    else:\n",
        "        raise ValueError(f\"Input shape not supported: {x.shape}\")\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Prepare dataset and dataloader\",DEVICE)\n",
        "drive.mount('/content/drive')\n",
        "def pad_collate(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    # Find max height, width, depth in this batch\n",
        "    max_h = max(x.shape[-3] for x in xs)\n",
        "    max_w = max(x.shape[-2] for x in xs)\n",
        "    max_d = max(x.shape[-1] for x in xs)\n",
        "    xs_padded = []\n",
        "    ys_padded = []\n",
        "    for x, y in zip(xs, ys):\n",
        "        pad_h = max_h - x.shape[-3]\n",
        "        pad_w = max_w - x.shape[-2]\n",
        "        pad_d = max_d - x.shape[-1]\n",
        "        # Pad as (left, right, top, bottom, front, back)\n",
        "        # F.pad uses (D1, D2, H1, H2, W1, W2) for 5D tensors\n",
        "        # For 4D tensors: (N, C, H, W, D) or (C, H, W, D)\n",
        "        # Here, x is likely (C, H, W, D)\n",
        "        x_padded = F.pad(x, (0, pad_d, 0, pad_w, 0, pad_h))\n",
        "        y_padded = F.pad(y, (0, pad_d, 0, pad_w, 0, pad_h))\n",
        "        xs_padded.append(x_padded)\n",
        "        ys_padded.append(y_padded)\n",
        "    xs_padded = torch.stack(xs_padded)\n",
        "    ys_padded = torch.stack(ys_padded)\n",
        "    return xs_padded, ys_padded\n",
        "\n",
        "def pad_or_crop_to_shape(x, target_shape):\n",
        "    # x: [B, C, D, H, W]\n",
        "    _, _, D, H, W = x.shape\n",
        "    tD, tH, tW = target_shape\n",
        "    # Pad\n",
        "    pad_d = max(tD - D, 0)\n",
        "    pad_h = max(tH - H, 0)\n",
        "    pad_w = max(tW - W, 0)\n",
        "    x = F.pad(x, [0, pad_w, 0, pad_h, 0, pad_d])\n",
        "    # Crop\n",
        "    x = x[:, :, :tD, :tH, :tW]\n",
        "    return x\n",
        "\n",
        "drive_path = '/content/drive/My Drive'  # Replace 'MyDrive' with the specific folder if needed\n",
        "\n",
        "# List all files and directories in the drive\n",
        "for item in os.listdir(drive_path):\n",
        "    item_path = os.path.join(drive_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "       print(item)\n",
        "\n",
        "train_dataset = ISLESDataset3D(\n",
        "    root_dir=DATA_DIR)\n",
        "sample_x, sample_y = train_dataset[0]\n",
        "print(\"Sample mask unique:\", torch.unique(sample_y))\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "print(f\"Number of samples in dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of batches in DataLoader: {len(train_loader)}\")\n",
        "\n",
        "print(f\"#Train multiple base models for ensemble\")\n",
        "for i in range(N_MODELS):\n",
        "    model = get_unet(in_channels=2).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        print(f\"Training model {i}, epoch {epoch+1}/{EPOCHS}\")\n",
        "       # ...existing code...\n",
        "    # In your training loop:\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        target_shape = (128, 128, 64)\n",
        "        # Ensure correct dims and type\n",
        "        if x.ndim == 4:\n",
        "            x = x.unsqueeze(0)\n",
        "        if x.ndim == 5 and x.shape[1] > 2:\n",
        "            x = x[:, :2, ...]\n",
        "        x = safe_pad_or_crop(x, target_shape)\n",
        "        x = x.to(DEVICE, dtype=torch.float)\n",
        "        # Mask handling\n",
        "        y = safe_unsqueeze_mask(y)\n",
        "        y = safe_pad_or_crop(y, target_shape)\n",
        "        y = y.to(DEVICE, dtype=torch.float)\n",
        "        y = y.clamp(0, 1)  # Ensure mask is binary/float\n",
        "\n",
        "        print(\"x shape:\", x.shape)\n",
        "        print(\"y shape:\", y.shape)      # [B, 2, H, W]\n",
        "        # No further slicing needed!  # [B, 2, H, W]\n",
        "\n",
        "        # For y (mask), shape: [B, D, H, W]\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        bce = torch.nn.BCELoss()\n",
        "        loss = 0.5 * bce(out, y) + 0.5 * (1 - dice_score(out, y))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"  Model {i} Epoch {epoch+1} Batch {batch_idx}/{len(train_loader)} Loss: {loss.item():.4f}\")\n",
        "# ...existing code...\n",
        "    torch.save(model.state_dict(), f\"base_model_{i}.pth\")\n",
        "    print(f\"Saved base_model_{i}.pth\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"#Load ensemble models\")\n",
        "model_paths = [f\"base_model_{i}.pth\" for i in range(N_MODELS)]\n",
        "ensemble_models = load_ensemble(model_paths, DEVICE)\n",
        "\n",
        "print(f\"#Ensemble prediction on a batch\")\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"Input min/max:\", x.min(), x.max())\n",
        "print(\"Mask unique values:\", torch.unique(y))\n",
        "x = x.to(DEVICE, dtype=torch.float)\n",
        "y = y.to(DEVICE, dtype=torch.float)\n",
        "if x.shape[1] > 2:\n",
        "    x = x[:, :2, ...]  # Ensure only 2 channels\n",
        "final_mask, averaged_probs = ensemble_predict(ensemble_models, x)  # Use full 3D volume\n",
        "\n",
        "# For visualization, take a middle slice\n",
        "mid_slice = x.shape[2] // 2  # D axis\n",
        "x_vis = x[:, :, mid_slice, :, :]  # [B, 2, H, W]\n",
        "y_vis = y[:, :, mid_slice, :, :] if y.ndim == 5 else y[:, mid_slice, :, :]\n",
        "final_mask_vis = final_mask[:, 0, mid_slice, :, :]  # [B, H, W]\n",
        "final_mask, averaged_probs = ensemble_predict(ensemble_models, x)\n",
        "\n",
        "print(f\"#Evaluate and visualize\")\n",
        "for i in range(min(3, x.shape[0])):  # Show up to 3 samples\n",
        "    print(f\"Dice score (ensemble): {dice_score(final_mask[i], y[i])}\")\n",
        "    plot_sample(x[i].cpu().squeeze(), y[i].cpu(), final_mask[i].cpu().squeeze(), channel=0)  # DWI\n",
        "    continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "kpMPdNc1DLgr",
        "outputId": "e0979474-ff72-4a1f-a533-619c8231579f"
      },
      "id": "kpMPdNc1DLgr",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Load ensemble models\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'N_MODELS' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1606627897>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"#Load ensemble models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"base_model_{i}.pth\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mensemble_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"#Ensemble prediction on a batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'N_MODELS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c6e2436",
      "metadata": {
        "id": "1c6e2436"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sample_colored(x, y, pred, channel=0):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "    img = x[channel]\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.imshow(y, cmap='Greens', alpha=0.3)      # Ground truth in green\n",
        "    ax.imshow(pred, cmap='Reds', alpha=0.3)     # Prediction in red\n",
        "    ax.set_title(\"Input + GT (green) + Pred (red)\")\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"#Load ensemble models\")\n",
        "model_paths = [f\"base_model_{i}.pth\" for i in range(N_MODELS)]\n",
        "ensemble_models = load_ensemble(model_paths, DEVICE)\n",
        "\n",
        "print(f\"#Ensemble prediction on a batch\")\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"Input min/max:\", x.min(), x.max())\n",
        "print(\"Mask unique values:\", torch.unique(y))\n",
        "x = x.to(DEVICE, dtype=torch.float)\n",
        "y = y.to(DEVICE, dtype=torch.float)\n",
        "if x.shape[1] > 2:\n",
        "    x = x[:, :2, ...]  # Ensure only 2 channels\n",
        "final_mask, averaged_probs = ensemble_predict(ensemble_models, x)  # Use full 3D volume\n",
        "\n",
        "# For visualization, take a middle slice\n",
        "mid_slice = x.shape[2] // 2  # D axis\n",
        "x_vis = x[:, :, mid_slice, :, :]  # [B, 2, H, W]\n",
        "y_vis = y[:, :, mid_slice, :, :] if y.ndim == 5 else y[:, mid_slice, :, :]\n",
        "final_mask_vis = final_mask[:, 0, mid_slice, :, :]  # [B, H, W]\n",
        "final_mask, averaged_probs = ensemble_predict(ensemble_models, x)\n",
        "\n",
        "print(f\"#Evaluate and visualize\")\n",
        "for i in range(min(3, x.shape[0])):  # Show up to 3 samples\n",
        "    # Find a slice with nonzero mask, else use middle\n",
        "    mask_3d = y[i, 0] if y.ndim == 5 else y[i]\n",
        "    nonzero_slices = torch.where(mask_3d.sum(dim=(-1, -2)) > 0)[0]\n",
        "    if len(nonzero_slices) > 0:\n",
        "        slice_idx = int(nonzero_slices[len(nonzero_slices)//2])\n",
        "    else:\n",
        "        slice_idx = x.shape[2] // 2  # fallback to middle\n",
        "\n",
        "    print(f\"Sample {i}: slice {slice_idx}, input min/max:\", x[i, 0, slice_idx].min().item(), x[i, 0, slice_idx].max().item())\n",
        "    print(f\"Sample {i}: mask unique:\", torch.unique(mask_3d[slice_idx]))\n",
        "    print(f\"Sample {i}: pred unique:\", torch.unique(final_mask[i, 0, slice_idx]))\n",
        "\n",
        "    x_slice = x[i, :, slice_idx, :, :].cpu().squeeze()  # [C, H, W] or [H, W]\n",
        "    y_slice = mask_3d[slice_idx].cpu().squeeze()\n",
        "    mask_slice = final_mask[i, 0, slice_idx, :, :].cpu().squeeze()\n",
        "    plot_sample_colored(x_slice, y_slice, mask_slice, channel=0)  # DWI\n",
        "    continue\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}